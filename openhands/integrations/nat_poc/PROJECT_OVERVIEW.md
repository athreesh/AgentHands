# NAT Agent Creation System: Complete Project Overview

**Last Updated**: December 2024
**Status**: Phase B - RL Training Ready
**Repository**: https://github.com/athreesh/AgentHands

---

## Executive Summary

This project trains **AgentHands** (a coding agent) to become an expert at creating complete NAT (NeMo Agent Toolkit) agents through Reinforcement Learning.

**Key Innovation**: We use RL to train AgentHands to excel at the complete workflowâ€”tool generation, integration, and validationâ€”while keeping Gemini for cheap, effective planning.

---

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER REQUEST                                 â”‚
â”‚  "I want a financial research agent..."                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              GEMINI 2.5 PRO PLANNER                             â”‚
â”‚              (Not RL trained - stays cheap)                     â”‚
â”‚                                                                 â”‚
â”‚  Analyzes user intent and creates plan:                        â”‚
â”‚    â€¢ Scaffold selection (react_agent, tool_calling_agent)      â”‚
â”‚    â€¢ MCP servers from smithery.ai                              â”‚
â”‚    â€¢ Custom tools specifications                               â”‚
â”‚    â€¢ Test cases for validation                                 â”‚
â”‚                                                                 â”‚
â”‚  Output: Complete AgentPlan                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AGENTHANDS AGENT â­                                â”‚
â”‚              (RL Trained with SkyRL)                            â”‚
â”‚                                                                 â”‚
â”‚  Base LLM: Qwen2.5-Coder-32B-Instruct                         â”‚
â”‚  Agent Type: CodeActAgent (multi-turn coding)                  â”‚
â”‚  Training: GRPO with SkyRL framework                           â”‚
â”‚                                                                 â”‚
â”‚  Creates complete NAT agents:                                   â”‚
â”‚    1. Generate all NAT tools (following patterns exactly)      â”‚
â”‚    2. Write comprehensive test suites                          â”‚
â”‚    3. Create YAML configuration files                          â”‚
â”‚    4. Set up MCP server integration scripts                    â”‚
â”‚    5. Validate end-to-end workflows                            â”‚
â”‚                                                                 â”‚
â”‚  Improves through RL training! ðŸš€                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SKYRL TRAINING LOOP                                â”‚
â”‚                                                                 â”‚
â”‚  For each training episode:                                     â”‚
â”‚    1. Sample NAT agent task from dataset                       â”‚
â”‚    2. AgentHands attempts to create complete agent            â”‚
â”‚    3. Validate:                                                 â”‚
â”‚       - Tools created and NAT compliant?                       â”‚
â”‚       - YAML config valid?                                     â”‚
â”‚       - MCP setup correct?                                     â”‚
â”‚       - End-to-end tests pass?                                 â”‚
â”‚    4. Calculate reward (0-2.0 scale)                           â”‚
â”‚    5. Update AgentHands policy via GRPO                        â”‚
â”‚                                                                 â”‚
â”‚  Result: AgentHands becomes NAT specialist                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              COMPLETE NAT AGENT                                 â”‚
â”‚                                                                 â”‚
â”‚  Deliverables:                                                  â”‚
â”‚    âœ… All NAT tools (nat_tools/*.py)                           â”‚
â”‚    âœ… All tests (tests/test_*.py)                              â”‚
â”‚    âœ… Agent config (agent_config.yml)                          â”‚
â”‚    âœ… MCP setup (setup_mcp.sh)                                 â”‚
â”‚    âœ… End-to-end validation passed                             â”‚
â”‚                                                                 â”‚
â”‚  Ready to deploy to end users! ðŸŽ‰                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Components

### 1. Gemini Planner (Phase A - Complete)

**File**: `gemini_planner.py`

**Purpose**: Creates comprehensive plans for NAT agents

**Input**: User request (natural language)

**Output**: `AgentPlan` containing:
- Scaffold type with reasoning
- MCP servers to use
- Custom tools to generate
- Test cases for validation
- YAML config template

**Status**: âœ… Complete, production-ready

**Cost**: ~$0.01-0.05 per plan (very cheap)

### 2. MCP Registry (Phase A - Complete)

**File**: `mcp_registry.py`

**Purpose**: Catalog of available MCP servers from smithery.ai

**Categories**:
- Financial: Yahoo Finance, Financial Modeling Prep
- Research: Exa Search, Linkup
- Data: Google Sheets, Airtable
- Code: GitHub, GitLab

**Status**: âœ… Complete

### 3. AgentHands Agent (Phase B - RL Training)

**What it is**: A coding agent (fork of OpenHands) powered by an LLM

**Base Model**: Qwen2.5-Coder-32B-Instruct

**What it does**:
- Multi-turn coding (create files, run commands, debug)
- Generates NAT-compliant tools
- Creates complete agent deliverables
- Validates everything works

**Training**: RL with SkyRL to specialize in NAT creation

**Status**: ðŸ”„ Ready for RL training

### 4. SkyRL Environment (Phase B - New)

**File**: `skyrl_integration/nat_agent_env.py`

**Purpose**: Defines the RL environment for training AgentHands

**Episode Structure**:
- **State**: Agent spec from Gemini (scaffold, tools, tests)
- **Actions**: AgentHands multi-turn coding
- **Reward**: Success at creating complete working agent
- **Done**: When agent signals completion or max turns reached

**Reward Function**:
```
reward = 0.30 * tool_generation_score +
         0.30 * integration_score +
         0.40 * workflow_score +
         bonuses - penalties

Bonuses:
  +1.0 for complete working agent
  +0.3 for efficiency (fewer turns)

Penalties:
  -0.5 for missing tools or config
```

**Status**: ðŸ”„ Implementation in progress

---

## Training Workflow

### Dataset Preparation

**Script**: `skyrl_integration/prepare_dataset.py`

**Process**:
1. Collect user requests (examples + synthetic)
2. Use Gemini to create agent plans for each
3. Extract specifications for RL training
4. Save as parquet files (train/val split)

**Output**:
- `train.parquet` (900 agent specs)
- `val.parquet` (100 agent specs)

### RL Training

**Framework**: SkyRL (Berkeley Sky Computing Lab)

**Algorithm**: GRPO (Group Relative Policy Optimization)

**Training Configuration**:
```bash
Model: Qwen2.5-Coder-32B-Instruct
Epochs: 100
Batch size: 128
Learning rate: 5e-7
GPUs: 8x H100
Training time: ~1-2 days
```

**Training Loop**:
```
For each epoch:
  For each batch:
    1. Sample 128 agent specs
    2. AgentHands creates agents (in parallel)
    3. Validate each agent
    4. Calculate rewards
    5. Update policy via GRPO

  Every 10 epochs:
    - Save checkpoint
    - Evaluate on validation set
    - Log metrics to WandB
```

### Expected Improvements

| Metric | Pre-Training | After 100 Epochs |
|--------|-------------|------------------|
| Success Rate | ~45% | ~85% |
| Tool Generation | 60% | 95% |
| Integration | 40% | 90% |
| Workflow Validation | 30% | 80% |
| Avg Turns | 25 | 18 |

---

## NAT Tool Pattern

AgentHands learns to generate tools following this exact pattern:

```python
from nat.data_models.function import FunctionBaseConfig
from nat.cli.register_workflow import register_function
from nat.builder.builder import Builder
from nat.builder.function_info import FunctionInfo
from pydantic import Field

class ToolNameConfig(FunctionBaseConfig, name="tool_name"):
    """Configuration for the tool"""
    description: str = Field(
        default="Tool description",
        description="What this tool does"
    )

@register_function(config_type=ToolNameConfig)
async def tool_name(config: ToolNameConfig, builder: Builder):
    """Tool implementation"""

    async def _arun(param: InputType) -> OutputType:
        """
        Async run method - the actual tool logic

        Args:
            param: Input parameter with type hints

        Returns:
            Output with type hints
        """
        # Implementation here
        result = perform_task(param)
        return result

    # Yield FunctionInfo (required by NAT)
    yield FunctionInfo.from_fn(_arun, description=config.description)
```

**Key Requirements**:
1. Config class inheriting from `FunctionBaseConfig`
2. `@register_function` decorator
3. Async `_arun` method
4. `yield FunctionInfo.from_fn()`
5. Type hints on all parameters
6. Comprehensive docstrings
7. Error handling

---

## Complete Agent Deliverables

After training, AgentHands creates complete agents with:

### 1. NAT Tools (`nat_tools/`)

```
nat_tools/
â”œâ”€â”€ tool_one.py          # NAT-compliant tool
â”œâ”€â”€ tool_two.py          # Following exact pattern
â””â”€â”€ tool_three.py        # With type hints & docs
```

### 2. Tests (`tests/`)

```
tests/
â”œâ”€â”€ test_tool_one.py     # 5+ test cases
â”œâ”€â”€ test_tool_two.py     # Normal + edge cases
â””â”€â”€ test_tool_three.py   # Error scenarios
```

### 3. Agent Configuration (`agent_config.yml`)

```yaml
llm:
  model_name: gpt-4-turbo

agent:
  type: react_agent

  tools:
    # MCP servers
    - id: yahoo_finance
      type: server_tool
      server_url: "${oc.env:YAHOO_FINANCE_URL}"

    # Custom tools
    - id: tool_one
      type: tool_one
    - id: tool_two
      type: tool_two
```

### 4. MCP Setup Script (`setup_mcp.sh`)

```bash
#!/bin/bash
# Install MCP servers from smithery.ai
npx @smithery/cli install @owner/yahoo-finance --client claude
npx @smithery/cli install exa --client claude
echo "âœ… MCP servers installed"
```

### 5. Validation Results

```
âœ… All tools created (3/3)
âœ… All tests pass (15/15)
âœ… YAML config valid
âœ… MCP setup complete
âœ… End-to-end tests pass (4/4)
ðŸŽ‰ Agent ready for deployment!
```

---

## File Structure

```
openhands/integrations/nat_poc/
â”œâ”€â”€ README.md                      # Quick start guide
â”œâ”€â”€ RL_TRAINING.md                 # Complete training guide
â”œâ”€â”€ PROJECT_OVERVIEW.md            # This file
â”‚
â”œâ”€â”€ gemini_planner.py              # Gemini 2.5 Pro planner
â”œâ”€â”€ mcp_registry.py                # MCP server catalog
â”œâ”€â”€ agenthands_executor.py         # AgentHands executor
â”œâ”€â”€ real_openhands_executor.py     # Real OpenHands executor
â”‚
â”œâ”€â”€ skyrl_integration/             # RL training components
â”‚   â”œâ”€â”€ nat_agent_env.py          # SkyRL environment
â”‚   â”œâ”€â”€ prepare_dataset.py         # Dataset generation
â”‚   â”œâ”€â”€ evaluate_model.py          # Model evaluation
â”‚   â””â”€â”€ deploy_trained.py          # Deployment utils
â”‚
â”œâ”€â”€ poc_simple_scenario.py         # Demo: Simple
â”œâ”€â”€ poc_financial_research.py      # Demo: Complex
â”œâ”€â”€ run_end_to_end.py              # Demo: E2E simulation
â””â”€â”€ run_real_e2e.py                # Demo: Real execution
```

---

## Development Phases

### âœ… Phase A: Foundation (Complete)
- Gemini planner working
- MCP registry populated
- NAT system prompt created
- End-to-end POC successful

### ðŸ”„ Phase B: RL Training (Current)
- SkyRL environment implemented
- Dataset preparation working
- Training configuration ready
- Ready to train

### ðŸ”œ Phase C: Production (Next)
- Trained model deployed
- API service for agent creation
- User feedback collection
- Continuous improvement

### ðŸ”œ Phase D: Scale (Future)
- Multi-domain specialists
- Human-in-the-loop training
- Agent marketplace
- Automated deployment

---

## Success Metrics

### Training Metrics
- **Mean Reward**: Tracks overall quality
- **Success Rate**: % of complete working agents
- **Tool Quality**: NAT pattern compliance
- **Integration Success**: YAML + MCP correctness
- **Workflow Pass Rate**: End-to-end test success

### Production Metrics
- **User Satisfaction**: Feedback ratings
- **Agent Deployment Rate**: % of agents deployed
- **First-Time Success**: Agents that work without iteration
- **Time to Deploy**: Minutes from request to working agent

---

## Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| Planning | Gemini 2.5 Pro | Create agent specifications |
| Coding Agent | AgentHands (OpenHands fork) | Generate code & validate |
| Base LLM | Qwen2.5-Coder-32B | Power the agent |
| RL Framework | SkyRL | Train the agent |
| RL Algorithm | GRPO | Policy optimization |
| Training Backend | FSDP2 | Distributed training |
| Inference | vLLM | Fast generation |
| Orchestration | Ray | Distributed execution |
| Logging | WandB | Experiment tracking |
| Target Framework | NAT | Agent deployment |

---

## Key Insights

### Why This Approach Works

1. **Division of Labor**
   - Gemini: Planning (what it's good at, cheap)
   - AgentHands: Implementation (what we train, specialized)

2. **RL Advantage**
   - Learns from successes and failures
   - Discovers patterns humans might miss
   - Improves over time with more data

3. **NAT Specialization**
   - Focused on one thing (NAT agents)
   - Clear success criteria (tests pass)
   - Immediate validation (does it work?)

4. **Practical Value**
   - Delivers complete, working agents
   - Ready to deploy (not just code snippets)
   - Real end-user value

### Challenges Overcome

1. **Tool Generation Quality**
   - Solution: RL reward for NAT pattern compliance

2. **Integration Complexity**
   - Solution: Include YAML + MCP in reward function

3. **Validation Reliability**
   - Solution: Automated test suites + end-to-end checks

4. **Training Efficiency**
   - Solution: SkyRL's optimized distributed training

---

## Getting Started

### Quick Test (No Training)
```bash
cd /path/to/AgentHands
python -m openhands.integrations.nat_poc.poc_simple_scenario
```

### Full RL Training
```bash
# 1. Prepare dataset
python -m openhands.integrations.nat_poc.skyrl_integration.prepare_dataset

# 2. Train with SkyRL
cd /path/to/SkyRL/skyrl-train
bash examples/nat_agent_creation/train_agenthands.sh

# 3. Evaluate
python -m openhands.integrations.nat_poc.skyrl_integration.evaluate_model

# 4. Deploy
python -m openhands.integrations.nat_poc.skyrl_integration.deploy_trained
```

---

## Resources

- **AgentHands Repo**: https://github.com/athreesh/AgentHands
- **SkyRL Docs**: https://skyrl.readthedocs.io
- **NAT Toolkit**: https://github.com/NVIDIA/NeMo-Agent-Toolkit
- **Smithery (MCP)**: https://smithery.ai
- **Questions**: Open issue in AgentHands repo

---

**Status**: Ready for RL training! ðŸš€

**Last Updated**: December 2024
